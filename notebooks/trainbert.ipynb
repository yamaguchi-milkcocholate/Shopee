{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intense-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from shutil import copyfile\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wrapped-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    outdir: str = \"../results\"\n",
    "    device: str = \"cuda:2\"\n",
    "    device_id: int = 2\n",
    "\n",
    "    datadir: str = '../data/tfrecord-skf'\n",
    "    modeldir: str = '../models/bert/bert_en_uncased_L-24_H-1024_A-16_3'\n",
    "    seed: int = 123\n",
    "    n_splits: int = 3\n",
    "    \n",
    "    # Training config\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 30\n",
    "    patience: int = 5\n",
    "    lr: float = 0.00001\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "animated-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "northern-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path().resolve()\n",
    "sys.path.append(os.path.abspath(base_dir / '../'))\n",
    "\n",
    "config_dict = {\n",
    "#     'epochs': 1,\n",
    "}\n",
    "\n",
    "config = Config().update(config_dict)\n",
    "config.to_yaml(base_dir / config.outdir / 'config.yaml')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.device_id)\n",
    "\n",
    "\n",
    "from src.tokenization import *\n",
    "from src.preprocess import *\n",
    "from src.text import *\n",
    "from src.model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>f1</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>0</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>1</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>3</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>4</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret            0   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...            1   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr            2   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...            3   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml            4   \n",
       "\n",
       "                             matches        f1  fold  \n",
       "0   train_129225211 train_2278313361  0.666667     1  \n",
       "1  train_3386243561 train_3423213080  0.666667     2  \n",
       "2  train_2288590299 train_3803689425  0.666667     5  \n",
       "3  train_2406599165 train_3342059966  0.666667     7  \n",
       "4   train_3369186413 train_921438619  0.666667     9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train = pd.read_csv(base_dir / config.datadir / 'train.csv')\n",
    "# train = prepare_dataset(df=train, n_splits=config.n_splits, seed=config.seed)\n",
    "\n",
    "train = pd.read_csv(base_dir / config.datadir / 'train_folds.csv')\n",
    "n_classes = train['label_group'].nunique()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_folds(fold: int):\n",
    "    train_folds, valid_folds = list(), list()\n",
    "    for i in range(train.fold.unique().shape[0]):\n",
    "        if i % config.n_splits == fold:\n",
    "            valid_folds += [i]\n",
    "        else:\n",
    "            train_folds += [i]\n",
    "            \n",
    "    return train_folds, valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "announced-gospel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_hub.keras_layer.KerasLayer at 0x7f8e2dd79950>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "radical-wrapping",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:235 call  *\n        result = smart_cond.smart_cond(training,\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py:509 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:780 __call__\n        result = self._call(*args, **kwds)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:823 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:697 _initialize\n        *args, **kwds))\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2855 _get_concrete_function_internal_garbage_collected\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3075 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:600 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py:257 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 70) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 70) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 70) dtype=int32>]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5eb6fcb82f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_bert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
      "\u001b[0;32m~/Shopee/src/model.py\u001b[0m in \u001b[0;36mbuild_bert_model\u001b[0;34m(bert_layer, n_classes, lr, max_len, train)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mclf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:235 call  *\n        result = smart_cond.smart_cond(training,\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py:509 _call_attribute  **\n        return instance.__call__(*args, **kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:780 __call__\n        result = self._call(*args, **kwds)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:823 _call\n        self._initialize(args, kwds, add_initializers_to=initializers)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:697 _initialize\n        *args, **kwds))\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:2855 _get_concrete_function_internal_garbage_collected\n        graph_function, _, _ = self._maybe_define_function(args, kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3213 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/function.py:3075 _create_graph_function\n        capture_by_value=self._capture_by_value),\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py:600 wrapped_fn\n        return weak_wrapped_fn().__wrapped__(*args, **kwds)\n    /home/yamaguchi-milkcocholate/anaconda3/envs/Shopee/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py:257 restored_function_body\n        \"\\n\\n\".join(signature_descriptions)))\n\n    ValueError: Could not find matching function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 70) dtype=int32>, <tf.Tensor 'inputs_1:0' shape=(None, 70) dtype=int32>, <tf.Tensor 'inputs_2:0' shape=(None, 70) dtype=int32>]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids'), 'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'), 'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n"
     ]
    }
   ],
   "source": [
    "for fold in range(config.n_splits):\n",
    "    if fold == 0:\n",
    "        continue\n",
    "    \n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    outdir = base_dir / config.outdir / f'fold-{fold}'\n",
    "    os.makedirs(str(outdir), exist_ok=True)\n",
    "    \n",
    "    train_folds, valid_folds = split_folds(fold=fold)\n",
    "    train_df, valid_df = train.query('fold in @train_folds'), train.query('fold in @valid_folds')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(str(base_dir / config.modeldir), trainable=True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    x_train = bert_encode(train_df['title'].values, tokenizer, max_len=70)\n",
    "    x_val = bert_encode(valid_df['title'].values, tokenizer, max_len=70)\n",
    "    y_train = train_df['label_group'].values\n",
    "    y_val = valid_df['label_group'].values\n",
    "    \n",
    "    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n",
    "    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
    "    \n",
    "    bert_model = build_bert_model(bert_layer, n_classes=n_classes, lr=config.lr, max_len=70)\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        str(outdir / (f'Bert_seed{config.seed}' + '_epoch{epoch:02d}.h5')),\n",
    "        monitor = 'val_loss', \n",
    "        verbose = 1, \n",
    "        save_best_only = True,\n",
    "        save_weights_only = True, \n",
    "        mode = 'min'\n",
    "    )\n",
    "\n",
    "    \n",
    "    history = bert_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data = (x_val, y_val),\n",
    "        epochs = config.epochs, \n",
    "        callbacks = [checkpoint],\n",
    "        batch_size = config.batch_size,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    pickle.dump(history.history, open(str(outdir / 'history.pkl'), 'wb'))\n",
    "    \n",
    "    del bert_model, bert_layer, train_df, valid_df, x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-imagination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
