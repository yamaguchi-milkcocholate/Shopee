{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "personalized-chicago",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from shutil import copyfile\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "positive-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    outdir: str = \"../results/groupkfold\"\n",
    "    device: str = \"cuda:2\"\n",
    "    device_id: int = 2\n",
    "\n",
    "    datadir: str = '../data/shopee-product-matching'\n",
    "    modeldir: str = '../models/bert/bert_en_uncased_L-24_H-1024_A-16_1'\n",
    "    seed: int = 123\n",
    "    n_splits: int = 5\n",
    "    \n",
    "    # Training config\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 50\n",
    "    patience: int = 5\n",
    "    lr: float = 0.00001\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "flush-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "insured-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path().resolve()\n",
    "sys.path.append(os.path.abspath(base_dir / '../'))\n",
    "\n",
    "config_dict = {\n",
    "#     'epochs': 1,\n",
    "}\n",
    "\n",
    "config = Config().update(config_dict)\n",
    "config.to_yaml(base_dir / config.outdir / 'config.yaml')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.device_id)\n",
    "\n",
    "from src.tokenization import *\n",
    "from src.preprocess import *\n",
    "from src.text import *\n",
    "from src.model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "utility-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>7572</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>10509</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret          666   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...         7572   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr         6172   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...        10509   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml         9425   \n",
       "\n",
       "                             matches  fold  \n",
       "0   train_129225211 train_2278313361     3  \n",
       "1  train_3386243561 train_3423213080     3  \n",
       "2  train_2288590299 train_3803689425     4  \n",
       "3  train_2406599165 train_3342059966     3  \n",
       "4   train_3369186413 train_921438619     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(base_dir / config.datadir / 'train.csv')\n",
    "train = prepare_gkf_dataset(df=train, n_splits=config.n_splits, seed=config.seed)\n",
    "n_classes = train['label_group'].nunique()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "automatic-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "857/857 [==============================] - 449s 524ms/step - loss: 23.6492 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 25.4444 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 22.1526 - sparse_categorical_accuracy: 0.0033\n",
      "Epoch 00002: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch02.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 22.1526 - sparse_categorical_accuracy: 0.0033 - val_loss: 25.9754 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 19.9552 - sparse_categorical_accuracy: 0.0115 - val_loss: 25.9680 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 17.5341 - sparse_categorical_accuracy: 0.0364\n",
      "Epoch 00004: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch04.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 17.5341 - sparse_categorical_accuracy: 0.0364 - val_loss: 25.9129 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "857/857 [==============================] - 447s 521ms/step - loss: 15.2368 - sparse_categorical_accuracy: 0.0674 - val_loss: 25.9404 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 13.1375 - sparse_categorical_accuracy: 0.1088\n",
      "Epoch 00006: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch06.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 13.1375 - sparse_categorical_accuracy: 0.1088 - val_loss: 25.9720 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 11.2751 - sparse_categorical_accuracy: 0.1531 - val_loss: 25.8870 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 9.6083 - sparse_categorical_accuracy: 0.2025\n",
      "Epoch 00008: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch08.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 9.6083 - sparse_categorical_accuracy: 0.2025 - val_loss: 26.0124 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 8.1021 - sparse_categorical_accuracy: 0.2674 - val_loss: 25.9662 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 6.8032 - sparse_categorical_accuracy: 0.3409\n",
      "Epoch 00010: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch10.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 6.8032 - sparse_categorical_accuracy: 0.3409 - val_loss: 26.0255 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 5.6384 - sparse_categorical_accuracy: 0.4290 - val_loss: 26.1069 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 4.6082 - sparse_categorical_accuracy: 0.5211\n",
      "Epoch 00012: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch12.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 4.6082 - sparse_categorical_accuracy: 0.5211 - val_loss: 26.1451 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 3.7315 - sparse_categorical_accuracy: 0.6156 - val_loss: 26.1636 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 2.9408 - sparse_categorical_accuracy: 0.7194\n",
      "Epoch 00014: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch14.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 2.9408 - sparse_categorical_accuracy: 0.7194 - val_loss: 26.2324 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 2.3035 - sparse_categorical_accuracy: 0.8139 - val_loss: 26.2645 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 1.7869 - sparse_categorical_accuracy: 0.8859\n",
      "Epoch 00016: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch16.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 1.7869 - sparse_categorical_accuracy: 0.8859 - val_loss: 26.3653 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 1.3488 - sparse_categorical_accuracy: 0.9379 - val_loss: 26.3673 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.9987 - sparse_categorical_accuracy: 0.9669\n",
      "Epoch 00018: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch18.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.9987 - sparse_categorical_accuracy: 0.9669 - val_loss: 26.3813 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.7264 - sparse_categorical_accuracy: 0.9792 - val_loss: 26.5660 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.5236 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 00020: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch20.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.5236 - sparse_categorical_accuracy: 0.9866 - val_loss: 26.5718 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.3853 - sparse_categorical_accuracy: 0.9890 - val_loss: 26.6589 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.3134 - sparse_categorical_accuracy: 0.9892\n",
      "Epoch 00022: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch22.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.3134 - sparse_categorical_accuracy: 0.9892 - val_loss: 26.7456 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.2673 - sparse_categorical_accuracy: 0.9891 - val_loss: 26.7048 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.2289 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 00024: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch24.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.2289 - sparse_categorical_accuracy: 0.9896 - val_loss: 26.7576 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.2258 - sparse_categorical_accuracy: 0.9877 - val_loss: 26.7182 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.2345 - sparse_categorical_accuracy: 0.9863\n",
      "Epoch 00026: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch26.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.2345 - sparse_categorical_accuracy: 0.9863 - val_loss: 26.8826 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "857/857 [==============================] - 447s 521ms/step - loss: 0.2116 - sparse_categorical_accuracy: 0.9877 - val_loss: 26.8017 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.2363 - sparse_categorical_accuracy: 0.9852\n",
      "Epoch 00028: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch28.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.2363 - sparse_categorical_accuracy: 0.9852 - val_loss: 26.9416 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "857/857 [==============================] - 447s 521ms/step - loss: 0.2174 - sparse_categorical_accuracy: 0.9879 - val_loss: 27.0365 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1845 - sparse_categorical_accuracy: 0.9884\n",
      "Epoch 00030: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch30.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1845 - sparse_categorical_accuracy: 0.9884 - val_loss: 27.0466 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.2019 - sparse_categorical_accuracy: 0.9864 - val_loss: 26.8663 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1668 - sparse_categorical_accuracy: 0.9897\n",
      "Epoch 00032: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch32.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9897 - val_loss: 27.0097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9910 - val_loss: 26.9408 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1758 - sparse_categorical_accuracy: 0.9888\n",
      "Epoch 00034: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch34.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1758 - sparse_categorical_accuracy: 0.9888 - val_loss: 27.0619 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1503 - sparse_categorical_accuracy: 0.9904 - val_loss: 27.1016 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1392 - sparse_categorical_accuracy: 0.9917\n",
      "Epoch 00036: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch36.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1392 - sparse_categorical_accuracy: 0.9917 - val_loss: 27.1031 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1530 - sparse_categorical_accuracy: 0.9907 - val_loss: 27.1078 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1604 - sparse_categorical_accuracy: 0.9901\n",
      "Epoch 00038: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch38.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1604 - sparse_categorical_accuracy: 0.9901 - val_loss: 27.1623 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9908 - val_loss: 27.2214 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1619 - sparse_categorical_accuracy: 0.9893\n",
      "Epoch 00040: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch40.h5\n",
      "857/857 [==============================] - 448s 522ms/step - loss: 0.1619 - sparse_categorical_accuracy: 0.9893 - val_loss: 27.1798 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9886 - val_loss: 27.0904 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1541 - sparse_categorical_accuracy: 0.9899\n",
      "Epoch 00042: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch42.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1541 - sparse_categorical_accuracy: 0.9899 - val_loss: 27.1726 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "857/857 [==============================] - 446s 521ms/step - loss: 0.1631 - sparse_categorical_accuracy: 0.9886 - val_loss: 27.1957 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1607 - sparse_categorical_accuracy: 0.9887\n",
      "Epoch 00044: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch44.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9887 - val_loss: 27.1410 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "857/857 [==============================] - 447s 521ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9902 - val_loss: 27.2972 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1369 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 00046: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch46.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1369 - sparse_categorical_accuracy: 0.9905 - val_loss: 27.2330 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "857/857 [==============================] - 447s 521ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9869 - val_loss: 27.3075 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1494 - sparse_categorical_accuracy: 0.9896\n",
      "Epoch 00048: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch48.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9896 - val_loss: 27.2499 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "857/857 [==============================] - 447s 522ms/step - loss: 0.1454 - sparse_categorical_accuracy: 0.9904 - val_loss: 27.2190 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "857/857 [==============================] - ETA: 0s - loss: 0.1439 - sparse_categorical_accuracy: 0.9902\n",
      "Epoch 00050: saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/groupkfold/fold-0/Bert_123_epoch50.h5\n",
      "857/857 [==============================] - 448s 523ms/step - loss: 0.1439 - sparse_categorical_accuracy: 0.9902 - val_loss: 27.2859 - val_sparse_categorical_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "for fold in range(config.n_splits):\n",
    "    seed_everything(config.seed)\n",
    "\n",
    "    outdir = base_dir / config.outdir / f'fold-{fold}'\n",
    "    os.makedirs(str(outdir), exist_ok=True)\n",
    "    \n",
    "    train_df, valid_df = train.query('fold != @fold'), train.query('fold == @fold')\n",
    "    \n",
    "    bert_layer = hub.KerasLayer(str(base_dir / config.modeldir), trainable=True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    x_train = bert_encode(train_df['title'].values, tokenizer, max_len=70)\n",
    "    x_val = bert_encode(valid_df['title'].values, tokenizer, max_len=70)\n",
    "    y_train = train_df['label_group'].values\n",
    "    y_val = valid_df['label_group'].values\n",
    "    \n",
    "    x_train = (x_train[0], x_train[1], x_train[2], y_train)\n",
    "    x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
    "    \n",
    "    bert_model = build_bert_model(bert_layer, n_classes=n_classes, lr=config.lr, max_len=70)\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        str(outdir / (f'Bert_{config.seed}' + '_epoch{epoch:02d}.h5')),\n",
    "        monitor = 'val_loss', \n",
    "        verbose = 1, \n",
    "        save_best_only = False,\n",
    "        save_weights_only = True, \n",
    "        mode = 'min',\n",
    "        period=2\n",
    "    )\n",
    "\n",
    "    \n",
    "    history = bert_model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data = (x_val, y_val),\n",
    "        epochs = config.epochs, \n",
    "        callbacks = [checkpoint],\n",
    "        batch_size = config.batch_size,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    pickle.dump(history.history, open(str(outdir / 'history.pkl'), 'wb'))\n",
    "    \n",
    "    del bert_model, bert_layer, train_df, valid_df, x_train, x_val, y_train, y_val\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-ultimate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
