{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from shutil import copyfile\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinct-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    outdir: str = \"../results/monitor\"\n",
    "    device: str = \"cuda:2\"\n",
    "    device_id: int = 2\n",
    "\n",
    "    datadir: str = '../data/shopee-product-matching'\n",
    "    modeldir: str = '../models/bert/bert_en_uncased_L-24_H-1024_A-16_1'\n",
    "    seed: int = 123\n",
    "    n_splits: int = 5\n",
    "    \n",
    "    # Training config\n",
    "    batch_size: int = 32\n",
    "    epochs: int = 100\n",
    "    patience: int = 5\n",
    "    lr: float = 0.00001\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "duplicate-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "former-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.device_id)\n",
    "\n",
    "base_dir = Path().resolve()\n",
    "sys.path.append(os.path.abspath(base_dir / '../'))\n",
    "\n",
    "from src.tokenization import *\n",
    "from src.preprocess import *\n",
    "from src.text import *\n",
    "from src.model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quantitative-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>7572</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>10509</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \\\n",
       "0                          Paper Bag Victoria Secret          666   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...         7572   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr         6172   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...        10509   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml         9425   \n",
       "\n",
       "                             matches  fold  \n",
       "0   train_129225211 train_2278313361     1  \n",
       "1  train_3386243561 train_3423213080     2  \n",
       "2  train_2288590299 train_3803689425     4  \n",
       "3  train_2406599165 train_3342059966     2  \n",
       "4   train_3369186413 train_921438619     4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(base_dir / config.datadir / 'train.csv')\n",
    "train = prepare_skf_dataset(df=train, n_splits=config.n_splits, seed=config.seed)\n",
    "n_classes = train['label_group'].nunique()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "olympic-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beginning-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "# _, valid_df = train.query('fold != @fold'), train.query('fold == @fold')\n",
    "valid_df = train\n",
    "\n",
    "bert_layer = hub.KerasLayer(str(base_dir / config.modeldir), trainable=True)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "x_val = bert_encode(valid_df['title'].values, tokenizer, max_len=70)\n",
    "# y_val = valid_df['label_group'].values\n",
    "# x_val = (x_val[0], x_val[1], x_val[2], y_val)\n",
    "\n",
    "bert_model = build_bert_model(bert_layer, n_classes=n_classes, lr=config.lr, max_len=70, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "robust-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = '04'\n",
    "bert_model.load_weights(str(base_dir / config.outdir / f'fold-{fold}' / f'Bert_{config.seed}_epoch{epoch}.h5'))\n",
    "bert_model = tf.keras.models.Model(inputs=bert_model.input[0:3], outputs=bert_model.layers[-4].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesbian-xerox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042b20e5b74646239f6723af13fcfd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk = 5000\n",
    "iterator = np.arange(np.ceil(len(valid_df) / chunk))\n",
    "\n",
    "embeds = []\n",
    "for j in tqdm(iterator):\n",
    "    a = int(j * chunk)\n",
    "    b = int((j + 1) * chunk)\n",
    "    text_chunk = ((x_val[0][a:b], x_val[1][a:b], x_val[2][a:b]))\n",
    "    text_embeddings = bert_model.predict(text_chunk, batch_size = config.batch_size)\n",
    "    embeds.append(text_embeddings)\n",
    "    \n",
    "del bert_model\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "olympic-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = np.concatenate(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cheap-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hairy-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = 50\n",
    "\n",
    "knn_model = NearestNeighbors(n_neighbors=KNN)\n",
    "knn_model.fit(text_embeddings)\n",
    "distances, indices = knn_model.kneighbors(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "waiting-container",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 15 is 0.5904284634407867\n",
      "Our f1 score for threshold 16 is 0.6078010907004866\n",
      "Our f1 score for threshold 17 is 0.6262444618870211\n",
      "Our f1 score for threshold 18 is 0.6433745287012458\n",
      "Our f1 score for threshold 19 is 0.6584849712437543\n",
      "Our f1 score for threshold 20 is 0.6720204720232597\n",
      "Our f1 score for threshold 21 is 0.681051074085284\n",
      "Our f1 score for threshold 22 is 0.6819029387826657\n",
      "Our f1 score for threshold 23 is 0.6703116962604577\n",
      "Our f1 score for threshold 24 is 0.6412431469730054\n",
      "Our f1 score for threshold 25 is 0.5858921261923475\n",
      "Our f1 score for threshold 26 is 0.49727332480622916\n",
      "Our f1 score for threshold 27 is 0.37089468430853184\n",
      "Our f1 score for threshold 28 is 0.23346265831060334\n",
      "Our f1 score for threshold 29 is 0.16819325287907133\n",
      "Our f1 score for threshold 30 is 0.16604049304791893\n",
      "Our f1 score for threshold 31 is 0.16604049304791893\n",
      "Our f1 score for threshold 32 is 0.16604049304791893\n",
      "Our f1 score for threshold 33 is 0.16604049304791893\n",
      "Our f1 score for threshold 34 is 0.16604049304791893\n"
     ]
    }
   ],
   "source": [
    "thresholds = list(np.arange(15, 35, 1))\n",
    "scores = []\n",
    "for threshold in thresholds:\n",
    "    predictions = []\n",
    "    for k in range(text_embeddings.shape[0]):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k, idx]\n",
    "        posting_ids = ' '.join(valid_df['posting_id'].iloc[ids].values)\n",
    "        predictions.append(posting_ids)\n",
    "    valid_df['pred_matches'] = predictions\n",
    "    valid_df['f1'] = f1_score(valid_df['matches'], valid_df['pred_matches'])\n",
    "    score = valid_df['f1'].mean()\n",
    "    print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "    scores.append(score)\n",
    "thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "desperate-albuquerque",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our f1 score for threshold 15 is 0.4690892731019354\n",
      "Our f1 score for threshold 16 is 0.47021160222525515\n",
      "Our f1 score for threshold 17 is 0.47149105556399534\n",
      "Our f1 score for threshold 18 is 0.4727997612684424\n",
      "Our f1 score for threshold 19 is 0.47412651321752763\n",
      "Our f1 score for threshold 20 is 0.47548494696068766\n",
      "Our f1 score for threshold 21 is 0.4757822644130587\n",
      "Our f1 score for threshold 22 is 0.475896577844836\n",
      "Our f1 score for threshold 23 is 0.47542861102884915\n",
      "Our f1 score for threshold 24 is 0.4725793451545964\n",
      "Our f1 score for threshold 25 is 0.4669689519704598\n",
      "Our f1 score for threshold 26 is 0.4566863675669318\n",
      "Our f1 score for threshold 27 is 0.4367305224294404\n",
      "Our f1 score for threshold 28 is 0.3967416351062135\n",
      "Our f1 score for threshold 29 is 0.30082482295270874\n",
      "Our f1 score for threshold 30 is 0.08783728392872799\n",
      "Our f1 score for threshold 31 is 0.05006093453515851\n",
      "Our f1 score for threshold 32 is 0.05006093453515851\n",
      "Our f1 score for threshold 33 is 0.05006093453515851\n",
      "Our f1 score for threshold 34 is 0.05006093453515851\n"
     ]
    }
   ],
   "source": [
    "thresholds = list(np.arange(15, 35, 1))\n",
    "scores = []\n",
    "for threshold in thresholds:\n",
    "    predictions = []\n",
    "    for k in range(text_embeddings.shape[0]):\n",
    "        idx = np.where(distances[k,] < threshold)[0]\n",
    "        ids = indices[k, idx]\n",
    "        posting_ids = ' '.join(valid_df['posting_id'].iloc[ids].values)\n",
    "        predictions.append(posting_ids)\n",
    "    valid_df['pred_matches'] = predictions\n",
    "    valid_df['f1'] = f1_score(valid_df['matches'], valid_df['pred_matches'])\n",
    "    score = valid_df['f1'].mean()\n",
    "    print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "    scores.append(score)\n",
    "thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "existing-james",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our best score is 0.8895570193870124 and has a threshold 23\n"
     ]
    }
   ],
   "source": [
    "max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "best_threshold = max_score['thresholds'].values[0]\n",
    "best_score = max_score['scores'].values[0]\n",
    "print(f'Our best score is {best_score} and has a threshold {best_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adolescent-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cacd7346f24ace97bd418a3f569cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use threshold\n",
    "predictions = []\n",
    "for k in range(text_embeddings.shape[0]):\n",
    "    idx = np.where(distances[k,] < 18.0)[0]\n",
    "    ids = indices[k, idx]\n",
    "    posting_ids = valid_df['posting_id'].iloc[ids].values\n",
    "    predictions.append(posting_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "verbal-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "unlike-committee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>matches</th>\n",
       "      <th>fold</th>\n",
       "      <th>pred_matches</th>\n",
       "      <th>f1</th>\n",
       "      <th>test_prediction</th>\n",
       "      <th>text_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>666</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>1</td>\n",
       "      <td>train_129225211 train_2278313361 train_1306907...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "      <td>[train_129225211, train_2278313361]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>7572</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "      <td>2</td>\n",
       "      <td>train_3386243561 train_3423213080 train_414821...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "      <td>[train_3386243561, train_3423213080]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>6172</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>4</td>\n",
       "      <td>train_2288590299 train_3803689425 train_980670...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_2288590299]</td>\n",
       "      <td>[train_2288590299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>10509</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>2</td>\n",
       "      <td>train_2406599165 train_1744956981 train_150810...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_2406599165, train_1744956981, train_150...</td>\n",
       "      <td>[train_2406599165, train_1744956981, train_150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>9425</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "      <td>4</td>\n",
       "      <td>train_3369186413 train_921438619 train_3944799...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "      <td>[train_3369186413, train_921438619]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34245</th>\n",
       "      <td>train_4028265689</td>\n",
       "      <td>fff1c07ceefc2c970a7964cfb81981c5.jpg</td>\n",
       "      <td>e3cd72389f248f21</td>\n",
       "      <td>Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...</td>\n",
       "      <td>9735</td>\n",
       "      <td>train_2829161572 train_4028265689</td>\n",
       "      <td>1</td>\n",
       "      <td>train_4028265689 train_2829161572 train_323845...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_4028265689, train_2829161572]</td>\n",
       "      <td>[train_4028265689, train_2829161572]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34246</th>\n",
       "      <td>train_769054909</td>\n",
       "      <td>fff401691371bdcb382a0d9075dfea6a.jpg</td>\n",
       "      <td>be86851f72e2853c</td>\n",
       "      <td>MamyPoko Pants Royal Soft - S 70 - Popok Celana</td>\n",
       "      <td>7038</td>\n",
       "      <td>train_1463059254 train_769054909</td>\n",
       "      <td>1</td>\n",
       "      <td>train_1463059254 train_769054909 train_2530102...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_1463059254, train_769054909]</td>\n",
       "      <td>[train_1463059254, train_769054909]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34247</th>\n",
       "      <td>train_614977732</td>\n",
       "      <td>fff421b78fa7284284724baf249f522e.jpg</td>\n",
       "      <td>ad27f0d08c0fcbf0</td>\n",
       "      <td>KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...</td>\n",
       "      <td>10537</td>\n",
       "      <td>train_4126022211 train_3926241003 train_232545...</td>\n",
       "      <td>4</td>\n",
       "      <td>train_614977732 train_512157627 train_9568348 ...</td>\n",
       "      <td>0.305085</td>\n",
       "      <td>[train_614977732, train_512157627, train_95683...</td>\n",
       "      <td>[train_614977732, train_512157627, train_95683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34248</th>\n",
       "      <td>train_3630949769</td>\n",
       "      <td>fff51b87916dbfb6d0f8faa01bee67b8.jpg</td>\n",
       "      <td>e3b13bd1d896c05c</td>\n",
       "      <td>Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...</td>\n",
       "      <td>4242</td>\n",
       "      <td>train_3419392575 train_1431563868 train_363094...</td>\n",
       "      <td>3</td>\n",
       "      <td>train_3630949769 train_3419392575 train_143156...</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>[train_3630949769, train_3419392575]</td>\n",
       "      <td>[train_3630949769, train_3419392575]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34249</th>\n",
       "      <td>train_1792180725</td>\n",
       "      <td>ffffa0ab2ae542357671e96254fa7167.jpg</td>\n",
       "      <td>af8bc4b2d2cf9083</td>\n",
       "      <td>FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...</td>\n",
       "      <td>1163</td>\n",
       "      <td>train_795128312 train_1792180725</td>\n",
       "      <td>4</td>\n",
       "      <td>train_1792180725 train_795128312 train_2662368...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>[train_1792180725, train_795128312]</td>\n",
       "      <td>[train_1792180725, train_795128312]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34250 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             posting_id                                 image  \\\n",
       "0       train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg   \n",
       "1      train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg   \n",
       "2      train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg   \n",
       "3      train_2406599165  00117e4fc239b1b641ff08340b429633.jpg   \n",
       "4      train_3369186413  00136d1cf4edede0203f32f05f660588.jpg   \n",
       "...                 ...                                   ...   \n",
       "34245  train_4028265689  fff1c07ceefc2c970a7964cfb81981c5.jpg   \n",
       "34246   train_769054909  fff401691371bdcb382a0d9075dfea6a.jpg   \n",
       "34247   train_614977732  fff421b78fa7284284724baf249f522e.jpg   \n",
       "34248  train_3630949769  fff51b87916dbfb6d0f8faa01bee67b8.jpg   \n",
       "34249  train_1792180725  ffffa0ab2ae542357671e96254fa7167.jpg   \n",
       "\n",
       "            image_phash                                              title  \\\n",
       "0      94974f937d4c2433                          Paper Bag Victoria Secret   \n",
       "1      af3f9460c2838f0f  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   \n",
       "2      b94cb00ed3e50f78        Maling TTS Canned Pork Luncheon Meat 397 gr   \n",
       "3      8514fc58eafea283  Daster Batik Lengan pendek - Motif Acak / Camp...   \n",
       "4      a6f319f924ad708c                  Nescafe \\xc3\\x89clair Latte 220ml   \n",
       "...                 ...                                                ...   \n",
       "34245  e3cd72389f248f21  Masker Bahan Kain Spunbond Non Woven 75 gsm 3 ...   \n",
       "34246  be86851f72e2853c    MamyPoko Pants Royal Soft - S 70 - Popok Celana   \n",
       "34247  ad27f0d08c0fcbf0  KHANZAACC Robot RE101S 1.2mm Subwoofer Bass Me...   \n",
       "34248  e3b13bd1d896c05c  Kaldu NON MSG HALAL Mama Kamu Ayam Kampung , S...   \n",
       "34249  af8bc4b2d2cf9083  FLEX TAPE PELAPIS BOCOR / ISOLASI AJAIB / ANTI...   \n",
       "\n",
       "       label_group                                            matches  fold  \\\n",
       "0              666                   train_129225211 train_2278313361     1   \n",
       "1             7572                  train_3386243561 train_3423213080     2   \n",
       "2             6172                  train_2288590299 train_3803689425     4   \n",
       "3            10509                  train_2406599165 train_3342059966     2   \n",
       "4             9425                   train_3369186413 train_921438619     4   \n",
       "...            ...                                                ...   ...   \n",
       "34245         9735                  train_2829161572 train_4028265689     1   \n",
       "34246         7038                   train_1463059254 train_769054909     1   \n",
       "34247        10537  train_4126022211 train_3926241003 train_232545...     4   \n",
       "34248         4242  train_3419392575 train_1431563868 train_363094...     3   \n",
       "34249         1163                   train_795128312 train_1792180725     4   \n",
       "\n",
       "                                            pred_matches        f1  \\\n",
       "0      train_129225211 train_2278313361 train_1306907...  0.076923   \n",
       "1      train_3386243561 train_3423213080 train_414821...  0.076923   \n",
       "2      train_2288590299 train_3803689425 train_980670...  0.076923   \n",
       "3      train_2406599165 train_1744956981 train_150810...  0.076923   \n",
       "4      train_3369186413 train_921438619 train_3944799...  0.076923   \n",
       "...                                                  ...       ...   \n",
       "34245  train_4028265689 train_2829161572 train_323845...  0.076923   \n",
       "34246  train_1463059254 train_769054909 train_2530102...  0.076923   \n",
       "34247  train_614977732 train_512157627 train_9568348 ...  0.305085   \n",
       "34248  train_3630949769 train_3419392575 train_143156...  0.113208   \n",
       "34249  train_1792180725 train_795128312 train_2662368...  0.076923   \n",
       "\n",
       "                                         test_prediction  \\\n",
       "0                    [train_129225211, train_2278313361]   \n",
       "1                   [train_3386243561, train_3423213080]   \n",
       "2                                     [train_2288590299]   \n",
       "3      [train_2406599165, train_1744956981, train_150...   \n",
       "4                    [train_3369186413, train_921438619]   \n",
       "...                                                  ...   \n",
       "34245               [train_4028265689, train_2829161572]   \n",
       "34246                [train_1463059254, train_769054909]   \n",
       "34247  [train_614977732, train_512157627, train_95683...   \n",
       "34248               [train_3630949769, train_3419392575]   \n",
       "34249                [train_1792180725, train_795128312]   \n",
       "\n",
       "                                         text_prediction  \n",
       "0                    [train_129225211, train_2278313361]  \n",
       "1                   [train_3386243561, train_3423213080]  \n",
       "2                                     [train_2288590299]  \n",
       "3      [train_2406599165, train_1744956981, train_150...  \n",
       "4                    [train_3369186413, train_921438619]  \n",
       "...                                                  ...  \n",
       "34245               [train_4028265689, train_2829161572]  \n",
       "34246                [train_1463059254, train_769054909]  \n",
       "34247  [train_614977732, train_512157627, train_95683...  \n",
       "34248               [train_3630949769, train_3419392575]  \n",
       "34249                [train_1792180725, train_795128312]  \n",
       "\n",
       "[34250 rows x 11 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-athletics",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
