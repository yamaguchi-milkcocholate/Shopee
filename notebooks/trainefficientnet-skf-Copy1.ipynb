{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mexican-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from typing import *\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from shutil import copyfile\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "agreed-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    outdir: str = \"../results/efficientnet\"\n",
    "    device: str = \"cuda:2\"\n",
    "    device_id: int = 2\n",
    "        \n",
    "    tf_expt: int = -1 # tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    datadir: str = '../data/tfrecord-skf'\n",
    "#     modeldir: str = '../models/bert/bert_en_uncased_L-24_H-1024_A-16_1'\n",
    "    seed: int = 123\n",
    "    valid_ratio: float = 0.25\n",
    "    image_size: List[int] = field(default_factory=lambda: [512, 512])\n",
    "    \n",
    "    # Training config\n",
    "    en_type: str = 'B3'\n",
    "    batch_size: int = 20\n",
    "    epochs: int = 20\n",
    "    lr: float = 0.001\n",
    "\n",
    "    def update(self, param_dict: Dict) -> \"Config\":\n",
    "        # Overwrite by `param_dict`\n",
    "        for key, value in param_dict.items():\n",
    "            if not hasattr(self, key):\n",
    "                raise ValueError(f\"[ERROR] Unexpected key for flag = {key}\")\n",
    "            setattr(self, key, value)\n",
    "        return self\n",
    "    \n",
    "    def to_yaml(self, filepath: str, width: int = 120):\n",
    "        with open(filepath, 'w') as f:\n",
    "            yaml.dump(asdict(self), f, width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "structured-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path().resolve()\n",
    "sys.path.append(os.path.abspath(base_dir / '../'))\n",
    "\n",
    "config_dict = {\n",
    "#     'epochs': 1,\n",
    "}\n",
    "config = Config().update(config_dict)\n",
    "config.to_yaml(base_dir / config.outdir / config.en_type / 'config.yaml')\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(config.device_id)\n",
    "\n",
    "from src.tokenization import *\n",
    "from src.preprocess import *\n",
    "from src.image import *\n",
    "from src.model import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eligible-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation function\n",
    "def data_augment(posting_id, image, label_group, matches):\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_hue(image, 0.01)\n",
    "    image = tf.image.random_saturation(image, 0.70, 1.30)\n",
    "    image = tf.image.random_contrast(image, 0.80, 1.20)\n",
    "    image = tf.image.random_brightness(image, 0.10)\n",
    "    return posting_id, image, label_group, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abstract-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size):\n",
    "    lr_start   = 0.000001\n",
    "    lr_max     = 0.000005 * 256\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 5\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.8\n",
    "   \n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max    \n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n",
    "        return lr\n",
    "\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closing-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baking-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_files = sorted(tf.io.gfile.glob(str(base_dir / config.datadir) + '/*.tfrec'))\n",
    "# train_files, valid_files = tfrecord_files[:int(len(tfrecord_files) * (1 - config.valid_ratio))], tfrecord_files[int(len(tfrecord_files) * (1 - config.valid_ratio)):]\n",
    "train_files, valid_files = tfrecord_files[int(len(tfrecord_files) * config.valid_ratio):], tfrecord_files[:int(len(tfrecord_files) * config.valid_ratio)]\n",
    "steps_per_epoch = count_data_items(train_files) // config.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supported-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11014"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(base_dir / config.datadir / 'train_folds.csv')\n",
    "n_classes = train['label_group'].nunique()\n",
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "minus-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.\n",
      "Epoch 1/20\n",
      "   2/1369 [..............................] - ETA: 10:39 - loss: 24.0947 - sparse_categorical_accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2543s vs `on_train_batch_end` time: 0.6798s). Check your callbacks.\n",
      "1369/1369 [==============================] - 1257s 918ms/step - loss: 23.9323 - sparse_categorical_accuracy: 0.0000e+00 - val_loss: 23.9779 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.00025680000000000006.\n",
      "Epoch 2/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 19.6608 - sparse_categorical_accuracy: 0.0101\n",
      "Epoch 00002: val_loss improved from inf to 18.76802, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_02.h5\n",
      "1369/1369 [==============================] - 1260s 920ms/step - loss: 19.6608 - sparse_categorical_accuracy: 0.0101 - val_loss: 18.7680 - val_sparse_categorical_accuracy: 0.0489\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0005126000000000001.\n",
      "Epoch 3/20\n",
      "1369/1369 [==============================] - 1259s 920ms/step - loss: 13.3743 - sparse_categorical_accuracy: 0.0817 - val_loss: 16.7236 - val_sparse_categorical_accuracy: 0.1208\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0007684000000000001.\n",
      "Epoch 4/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 9.3297 - sparse_categorical_accuracy: 0.1736\n",
      "Epoch 00004: val_loss improved from 18.76802 to 15.80607, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_04.h5\n",
      "1369/1369 [==============================] - 1265s 924ms/step - loss: 9.3297 - sparse_categorical_accuracy: 0.1736 - val_loss: 15.8061 - val_sparse_categorical_accuracy: 0.1569\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010242.\n",
      "Epoch 5/20\n",
      "1369/1369 [==============================] - 1262s 922ms/step - loss: 7.3424 - sparse_categorical_accuracy: 0.2483 - val_loss: 15.5486 - val_sparse_categorical_accuracy: 0.1817\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.00128.\n",
      "Epoch 6/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 6.3064 - sparse_categorical_accuracy: 0.3042\n",
      "Epoch 00006: val_loss improved from 15.80607 to 15.42949, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_06.h5\n",
      "1369/1369 [==============================] - 1262s 922ms/step - loss: 6.3064 - sparse_categorical_accuracy: 0.3042 - val_loss: 15.4295 - val_sparse_categorical_accuracy: 0.1808\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010242.\n",
      "Epoch 7/20\n",
      "1369/1369 [==============================] - 1259s 920ms/step - loss: 4.3500 - sparse_categorical_accuracy: 0.4688 - val_loss: 14.7503 - val_sparse_categorical_accuracy: 0.2665\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0008195600000000003.\n",
      "Epoch 8/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 2.9496 - sparse_categorical_accuracy: 0.6208\n",
      "Epoch 00008: val_loss improved from 15.42949 to 14.53271, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_08.h5\n",
      "1369/1369 [==============================] - 1260s 921ms/step - loss: 2.9496 - sparse_categorical_accuracy: 0.6208 - val_loss: 14.5327 - val_sparse_categorical_accuracy: 0.2933\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0006558480000000003.\n",
      "Epoch 9/20\n",
      "1369/1369 [==============================] - 1258s 919ms/step - loss: 2.0504 - sparse_categorical_accuracy: 0.7318 - val_loss: 14.3866 - val_sparse_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0005248784000000002.\n",
      "Epoch 10/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 1.4542 - sparse_categorical_accuracy: 0.8164\n",
      "Epoch 00010: val_loss improved from 14.53271 to 14.29328, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_10.h5\n",
      "1369/1369 [==============================] - 1259s 920ms/step - loss: 1.4542 - sparse_categorical_accuracy: 0.8164 - val_loss: 14.2933 - val_sparse_categorical_accuracy: 0.3329\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0004201027200000002.\n",
      "Epoch 11/20\n",
      "1369/1369 [==============================] - 1258s 919ms/step - loss: 1.0252 - sparse_categorical_accuracy: 0.8827 - val_loss: 14.1900 - val_sparse_categorical_accuracy: 0.3452\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0003362821760000002.\n",
      "Epoch 12/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 0.7484 - sparse_categorical_accuracy: 0.9251\n",
      "Epoch 00012: val_loss improved from 14.29328 to 14.14295, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_12.h5\n",
      "1369/1369 [==============================] - 1262s 922ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.9251 - val_loss: 14.1430 - val_sparse_categorical_accuracy: 0.3473\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.00026922574080000017.\n",
      "Epoch 13/20\n",
      "1369/1369 [==============================] - 1258s 919ms/step - loss: 0.5627 - sparse_categorical_accuracy: 0.9510 - val_loss: 14.0688 - val_sparse_categorical_accuracy: 0.3554\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.00021558059264000014.\n",
      "Epoch 14/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 0.4454 - sparse_categorical_accuracy: 0.9642\n",
      "Epoch 00014: val_loss improved from 14.14295 to 14.02541, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_14.h5\n",
      "1369/1369 [==============================] - 1258s 919ms/step - loss: 0.4454 - sparse_categorical_accuracy: 0.9642 - val_loss: 14.0254 - val_sparse_categorical_accuracy: 0.3557\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0001726644741120001.\n",
      "Epoch 15/20\n",
      "1369/1369 [==============================] - 1257s 918ms/step - loss: 0.3781 - sparse_categorical_accuracy: 0.9725 - val_loss: 14.0800 - val_sparse_categorical_accuracy: 0.3573\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0001383315792896001.\n",
      "Epoch 16/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 0.3133 - sparse_categorical_accuracy: 0.9782\n",
      "Epoch 00016: val_loss did not improve from 14.02541\n",
      "1369/1369 [==============================] - 1261s 921ms/step - loss: 0.3133 - sparse_categorical_accuracy: 0.9782 - val_loss: 14.0487 - val_sparse_categorical_accuracy: 0.3580\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.00011086526343168008.\n",
      "Epoch 17/20\n",
      "1369/1369 [==============================] - 1261s 921ms/step - loss: 0.2818 - sparse_categorical_accuracy: 0.9800 - val_loss: 14.0252 - val_sparse_categorical_accuracy: 0.3615\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 8.889221074534406e-05.\n",
      "Epoch 18/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 0.2529 - sparse_categorical_accuracy: 0.9815\n",
      "Epoch 00018: val_loss improved from 14.02541 to 13.99179, saving model to /home/yamaguchi-milkcocholate/Shopee/notebooks/../results/efficientnet/B3/EfficientNetB3_123_18.h5\n",
      "1369/1369 [==============================] - 1265s 924ms/step - loss: 0.2529 - sparse_categorical_accuracy: 0.9815 - val_loss: 13.9918 - val_sparse_categorical_accuracy: 0.3633\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 7.131376859627525e-05.\n",
      "Epoch 19/20\n",
      "1369/1369 [==============================] - 1257s 918ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9831 - val_loss: 14.0014 - val_sparse_categorical_accuracy: 0.3635\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 5.725101487702021e-05.\n",
      "Epoch 20/20\n",
      "1369/1369 [==============================] - ETA: 0s - loss: 0.2189 - sparse_categorical_accuracy: 0.9840\n",
      "Epoch 00020: val_loss did not improve from 13.99179\n",
      "1369/1369 [==============================] - 1257s 918ms/step - loss: 0.2189 - sparse_categorical_accuracy: 0.9840 - val_loss: 13.9985 - val_sparse_categorical_accuracy: 0.3657\n"
     ]
    }
   ],
   "source": [
    "seed_everything(config.seed)\n",
    "\n",
    "outdir = base_dir / config.outdir / config.en_type\n",
    "\n",
    "train_dataset = get_training_dataset(train_files, config, data_augment)\n",
    "train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "\n",
    "valid_dataset = get_validation_dataset(valid_files, config, data_augment)\n",
    "valid_dataset = valid_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n",
    "\n",
    "model = build_efficientnet_model(\n",
    "    n_classes=n_classes,\n",
    "    image_size=config.image_size,\n",
    "    lr=config.lr,\n",
    "    en_type=config.en_type,\n",
    "    train=True\n",
    ")\n",
    "\n",
    "# Model checkpoint\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    str(outdir / (f'EfficientNet{config.en_type}_{config.seed}_' + '{epoch:02d}.h5')),\n",
    "    monitor = 'val_loss', \n",
    "    verbose = 1, \n",
    "    save_best_only = True,\n",
    "    save_weights_only = True,\n",
    "    mode = 'min',\n",
    "    period=2\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs = config.epochs,\n",
    "    callbacks = [checkpoint, get_lr_callback(config.batch_size)], \n",
    "    validation_data = valid_dataset,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "pickle.dump(history.history, open(str(outdir / 'history.pkl'), 'wb'))\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
